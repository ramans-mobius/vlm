name: Build GIT Image To Text Model
description: Builds a pure GIT model for image captioning
inputs:
  - name: tokenizer_json
    type: Model
  - name: language_model_name
    type: String
    default: "microsoft/git-base"
  - name: domain_specialization
    type: String
    default: "general"
outputs:
  - name: model_config
    type: Data
  - name: model_weights
    type: Model
  - name: model_py
    type: Data
  - name: schema_json
    type: Data
implementation:
  container:
    image: gurpreetgandhi/nesy-factory:v29
    command:
      - sh
      - -c
      - |
        python3 -c "
        import sys, os, json, torch
        
        print('Number of arguments:', len(sys.argv))
        print('Arguments:', sys.argv)
        
        # Get arguments - SIMPLIFIED (no vision encoder config)
        tokenizer_json_path = sys.argv[1]
        language_model_name = sys.argv[2]
        domain_specialization = sys.argv[3]
        model_config_path = sys.argv[4]
        model_weights_path = sys.argv[5]
        model_py_path = sys.argv[6]
        schema_output_path = sys.argv[7]

        print('Building pure GIT model...')
        print('Tokenizer path: ' + tokenizer_json_path)
        print('Language model: ' + language_model_name)
        print('Domain specialization: ' + domain_specialization)

        # Create GIT model configuration
        model_config = {
            'model_type': 'git',
            'task': 'image_captioning',
            'language_model': language_model_name,
            'domain_specialization': domain_specialization,
            'vocab_size': 50257,  # GIT default
            'max_caption_length': 128,
            'image_size': 224,
            'device': 'cuda' if torch.cuda.is_available() else 'cpu'
        }

        # Generate GIT model code
        model_code = '''import torch
        from transformers import GitForCausalLM, GitProcessor
        
        class GITImageCaptioningModel:
            def __init__(self, config):
                self.config = config
                self.model = GitForCausalLM.from_pretrained(config['language_model'])
                self.processor = GitProcessor.from_pretrained(config['language_model'])
                
            def to(self, device):
                self.model = self.model.to(device)
                return self
                
            def train(self):
                self.model.train()
                
            def eval(self):
                self.model.eval()
                
            def forward(self, images, input_ids=None, attention_mask=None, labels=None):
                # Process images and text
                inputs = self.processor(
                    images=images,
                    text=None if input_ids is None else [''],  # placeholder
                    return_tensors='pt',
                    padding=True,
                    truncation=True
                )
                
                if input_ids is not None:
                    inputs['input_ids'] = input_ids
                    inputs['attention_mask'] = attention_mask
                    
                # Forward pass
                return self.model(**inputs, labels=labels)
                
            def generate(self, images, max_length=128, temperature=1.0):
                self.eval()
                inputs = self.processor(images=images, return_tensors='pt')
                return self.model.generate(
                    **inputs,
                    max_length=max_length,
                    temperature=temperature,
                    do_sample=True
                )
        '''

        # Ensure output directories exist
        os.makedirs(os.path.dirname(model_config_path), exist_ok=True)
        os.makedirs(os.path.dirname(model_weights_path), exist_ok=True)
        os.makedirs(os.path.dirname(model_py_path), exist_ok=True)
        os.makedirs(os.path.dirname(schema_output_path), exist_ok=True)

        # Save model config
        with open(model_config_path, 'w') as f:
            json.dump(model_config, f, indent=2)

        # Save model code
        with open(model_py_path, 'w') as f:
            f.write(model_code)

        # Create initial weights info
        initial_state = {
            'model_type': 'git',
            'config': model_config,
            'status': 'initialized',
            'pipeline_compatible': True
        }
        
        torch.save(initial_state, model_weights_path)

        # Save schema
        schema = {
            'model_type': 'git',
            'architecture': 'pure_git',
            'status': 'built',
            'pipeline_compatible': True
        }
        
        with open(schema_output_path, 'w') as f:
            json.dump(schema, f, indent=2)

        print('Pure GIT model built successfully!')
        " "$0" "$1" "$2" "$3" "$4" "$5" "$6"
    args:
      - {inputPath: tokenizer_json}
      - {inputValue: language_model_name}
      - {inputValue: domain_specialization}
      - {outputPath: model_config}
      - {outputPath: model_weights}
      - {outputPath: model_py}
      - {outputPath: schema_json}

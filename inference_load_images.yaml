name: Inference Load Images
description: Universal test image loader - works with ANY data source for inference.
inputs:
  - {name: test_source, type: String, description: 'Any source: huggingface, cdn, or reuse_training'}
  - {name: source_config, type: String, default: "{}", description: 'JSON config for the source'}
  - {name: num_samples, type: Integer, default: "50", description: 'Number of test samples'}
  - {name: test_type, type: String, default: "holdout", description: 'holdout, separate, or custom'}
outputs:
  - {name: test_images, type: Dataset}
  - {name: test_metadata, type: DatasetInfo}
  - {name: schema_json, type: Data}
implementation:
  container:
    image: gurpreetgandhi/nesy-factory:v29
    command:
      - sh
      - -c
      - |
        python3 -c "
        import sys, os, pickle, json, base64, io, zipfile, random
        from urllib.parse import unquote
        import requests
        from datasets import load_dataset
        from PIL import Image
        import numpy as np
        
        print('Number of arguments:', len(sys.argv))
        print('Arguments:', sys.argv)
        
        # Get arguments from command line
        test_source = sys.argv[1].strip()
        source_config = sys.argv[2]
        num_samples = int(sys.argv[3])
        test_type = sys.argv[4]
        test_images_path = sys.argv[5]
        test_metadata_path = sys.argv[6]
        schema_output_path = sys.argv[7]

        print('Starting test image loading...')
        print('Test source: ' + test_source)
        print('Source config: ' + source_config)
        print('Num samples: ' + str(num_samples))
        print('Test type: ' + test_type)

        # Parse config
        try:
            config = json.loads(source_config) if source_config and source_config.strip() not in ['{}', ''] else {}
        except json.JSONDecodeError as e:
            print('WARN: Invalid source_config JSON: ' + str(e) + ', using empty config')
            config = {}

        def load_cdn_test(source, config, num_samples, test_type):
            # Handle both cdn:// protocol and direct URLs
            if source.startswith('cdn://'):
                actual_url = source.replace('cdn://', '')
            elif source.startswith(('http://', 'https://')):
                actual_url = source
            else:
                raise ValueError('Unsupported test source: ' + source)
                
            caption_strategy = config.get('caption_strategy', 'folder_based')
            
            print('Loading CDN test images: ' + actual_url)
            
            # Download ZIP with URL decoding
            decoded_url = unquote(actual_url)
            print('Decoded URL: ' + decoded_url)
            
            headers = {'User-Agent': 'Mozilla/5.0'}
            response = requests.get(decoded_url, headers=headers, timeout=60)
            response.raise_for_status()
            
            zip_content = io.BytesIO(response.content)
            test_data = []
            
            with zipfile.ZipFile(zip_content, 'r') as zip_file:
                image_files = []
                for file_path in zip_file.namelist():
                    lower_path = file_path.lower()
                    if any(lower_path.endswith(ext) for ext in ['.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.webp']):
                        image_files.append(file_path)
                
                print('Found ' + str(len(image_files)) + ' image files in ZIP')
                
                # For testing, we might want a random subset
                if test_type == 'holdout':
                    # Use a percentage for testing
                    test_count = min(num_samples, int(len(image_files) * 0.2))
                    test_files = random.sample(image_files, test_count)
                else:
                    test_files = image_files[:num_samples]
                
                for i, file_path in enumerate(test_files):
                    try:
                        with zip_file.open(file_path) as image_file:
                            image_data = image_file.read()
                            
                            # Verify it's a valid image
                            try:
                                image = Image.open(io.BytesIO(image_data))
                                image.verify()
                            except Exception as e:
                                print('Skipping invalid image ' + file_path + ': ' + str(e))
                                continue
                            
                            base64_image = base64.b64encode(image_data).decode('utf-8')
                            
                            # Generate ground truth caption
                            ground_truth = generate_ground_truth_caption(file_path, caption_strategy)
                            
                            test_data.append({
                                'image_data': base64_image,
                                'ground_truth_caption': ground_truth,
                                'sample_id': i,
                                'filename': file_path,
                                'image_size': get_image_size_from_bytes(image_data),
                                'has_ground_truth': True,
                                'caption_strategy': caption_strategy
                            })
                    except Exception as e:
                        print('Skipping ' + file_path + ': ' + str(e))
                        continue

            metadata = {
                'source_type': 'cdn_zip',
                'cdn_url': actual_url,
                'total_test_samples': len(test_data),
                'has_ground_truth': True,
                'caption_strategy': caption_strategy,
                'test_type': test_type
            }
            
            return test_data, metadata

        def load_hf_test(source, config, num_samples, test_type):
            dataset_name = source.replace('huggingface://', '')
            split = config.get('split', 'validation')
            
            print('Loading HF test split: ' + split + ' from ' + dataset_name)
            
            try:
                dataset = load_dataset(dataset_name, split=split)
            except:
                # Try with default split
                dataset = load_dataset(dataset_name)
                if 'test' in dataset:
                    split = 'test'
                elif 'validation' in dataset:
                    split = 'validation'
                else:
                    split = 'train'
                dataset = dataset[split]
            
            test_data = []
            
            for i in range(min(num_samples, len(dataset))):
                try:
                    item = dataset[i]
                    image = item['image']
                    ground_truth = item.get('text', item.get('caption', ''))
                    
                    base64_image = image_to_base64(image)
                    
                    test_data.append({
                        'image_data': base64_image,
                        'ground_truth_caption': ground_truth,
                        'sample_id': i,
                        'image_size': get_image_size(image),
                        'has_ground_truth': bool(ground_truth),
                        'split': split
                    })
                except Exception as e:
                    print('Skipping test sample ' + str(i) + ': ' + str(e))
                    continue

            metadata = {
                'source_type': 'huggingface',
                'dataset_name': dataset_name,
                'split': split,
                'total_test_samples': len(test_data),
                'has_ground_truth': any(item['has_ground_truth'] for item in test_data)
            }
            
            return test_data, metadata

        def generate_ground_truth_caption(file_path, strategy):
            filename = os.path.splitext(os.path.basename(file_path))[0]
            path_parts = [p for p in file_path.split('/') if p]
            
            if strategy == 'folder_based' and len(path_parts) > 1:
                class_name = path_parts[-2]
                return 'A ' + class_name.replace('_', ' ')
            elif strategy == 'filename_based':
                return 'An image of ' + filename.replace('_', ' ')
            else:
                if len(path_parts) > 1:
                    class_name = path_parts[-2]
                    return 'A ' + class_name.replace('_', ' ') + ' showing ' + filename.replace('_', ' ')
                else:
                    return 'An image of ' + filename.replace('_', ' ')

        def image_to_base64(image):
            if isinstance(image, Image.Image):
                img_buffer = io.BytesIO()
                image.save(img_buffer, format='PNG')
                return base64.b64encode(img_buffer.getvalue()).decode('utf-8')
            else:
                pil_image = Image.fromarray(np.array(image))
                img_buffer = io.BytesIO()
                pil_image.save(img_buffer, format='PNG')
                return base64.b64encode(img_buffer.getvalue()).decode('utf-8')

        def get_image_size(image):
            if hasattr(image, 'size'):
                return image.size
            elif hasattr(image, 'shape'):
                return (image.shape[1], image.shape[0])
            else:
                return 'unknown'

        def get_image_size_from_bytes(image_data):
            try:
                image = Image.open(io.BytesIO(image_data))
                return image.size
            except:
                return 'unknown'

        # Route to appropriate loader
        if test_source.startswith('huggingface://'):
            test_data, metadata = load_hf_test(test_source, config, num_samples, test_type)
        elif test_source.startswith('cdn://') or test_source.startswith(('http://', 'https://')):
            test_data, metadata = load_cdn_test(test_source, config, num_samples, test_type)
        else:
            raise ValueError('Unsupported test source: ' + test_source)

        # Ensure output directories exist
        os.makedirs(os.path.dirname(test_images_path) or '.', exist_ok=True)
        with open(test_images_path, 'wb') as f:
            pickle.dump(test_data, f)

        os.makedirs(os.path.dirname(test_metadata_path) or '.', exist_ok=True)
        with open(test_metadata_path, 'wb') as f:
            pickle.dump(metadata, f)

        schema = {
            'test_source': test_source,
            'test_type': test_type,
            'test_samples_loaded': len(test_data),
            'has_ground_truth': metadata.get('has_ground_truth', False)
        }
        
        os.makedirs(os.path.dirname(schema_output_path) or '.', exist_ok=True)
        with open(schema_output_path, 'w') as f:
            json.dump(schema, f, indent=2)

        print('Test image loading complete! Loaded ' + str(len(test_data)) + ' test images')
        " "$0" "$1" "$2" "$3" "$4" "$5" "$6"
    args:
      - {inputValue: test_source}
      - {inputValue: source_config}
      - {inputValue: num_samples}
      - {inputValue: test_type}
      - {outputPath: test_images}
      - {outputPath: test_metadata}
      - {outputPath: schema_json}

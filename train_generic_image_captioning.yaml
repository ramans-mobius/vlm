name: Train Generic Image Captioning
description: Trains a generic image captioning model suitable for any domain using nesy-factory components.
inputs:
  - name: tokenizer_json
    type: Model
  - name: vision_encoder_config
    type: Data
  - name: model_config
    type: Data
  - name: model_weights
    type: Model
  - name: model_py
    type: Data
  - name: caption_dataset
    type: Dataset
  - name: dataset_metadata
    type: DatasetInfo
  - name: training_parameters
    type: String
    default: "{}"
    description: 'JSON string with training parameters (learning_rate, num_epochs, etc.)'
outputs:
  - name: trained_model
    type: Model
  - name: training_report
    type: Data
  - name: loss_curves
    type: Data
  - name: schema_json
    type: Data
implementation:
  container:
    image: gurpreetgandhi/nesy-factory:v29
    command:
      - sh
      - -c
      - |
        python3 -c "
        import sys, os, json, pickle, torch
        
        # FIX: Apply compatibility patch before any other imports
        try:
            from torch._dynamo.utils import warn_once
        except ImportError:
            print('Applying torch compatibility patch...')
            import torch._dynamo.utils
            if not hasattr(torch._dynamo.utils, 'warn_once'):
                def warn_once(*args, **kwargs):
                    print(f'WARN: {args[0] if args else \"\"}')
                torch._dynamo.utils.warn_once = warn_once
            print('Compatibility patch applied successfully')
        
        print('Number of arguments:', len(sys.argv))
        print('Arguments:', sys.argv)
        
        # Get arguments from command line - SAME LAYOUT
        tokenizer_json_path = sys.argv[1]
        vision_encoder_config_path = sys.argv[2]
        model_config_path = sys.argv[3]
        model_weights_path = sys.argv[4]
        model_py_path = sys.argv[5]
        caption_dataset_path = sys.argv[6]
        dataset_metadata_path = sys.argv[7]
        training_params_str = sys.argv[8]  # JSON string from user
        trained_model_path = sys.argv[9]
        training_report_path = sys.argv[10]
        loss_curves_path = sys.argv[11]
        schema_output_path = sys.argv[12]

        print('Starting generic image captioning training...')
        print('Training parameters string:', training_params_str)

        # Load model config from parent brick (file path)
        with open(model_config_path, 'r') as f:
            model_config = json.load(f)
        print('Loaded model config from parent brick')

        # FIXED: Better JSON parsing with escape sequence handling
        training_params = {}
        if training_params_str and training_params_str.strip() not in ['{}', '']:
            try:
                # First, try direct parsing
                training_params = json.loads(training_params_str)
                print('‚úÖ Successfully parsed training parameters (direct)')
            except json.JSONDecodeError as e1:
                try:
                    # If direct fails, it might have shell escapes - try unescaping
                    import ast
                    # Handle common escape sequences
                    unescaped_str = training_params_str.encode('utf-8').decode('unicode_escape')
                    training_params = json.loads(unescaped_str)
                    print('‚úÖ Successfully parsed training parameters (with unescaping)')
                except (json.JSONDecodeError, UnicodeDecodeError, SyntaxError) as e2:
                    try:
                        # Last resort: try literal eval for complex cases
                        training_params = ast.literal_eval(training_params_str)
                        print('‚úÖ Successfully parsed training parameters (with ast)')
                    except (ValueError, SyntaxError) as e3:
                        print('‚ùå WARN: All parsing attempts failed for training_parameters:')
                        print('   Direct error:', e1)
                        print('   Unescape error:', e2)
                        print('   AST error:', e3)
                        print('   Raw input:', repr(training_params_str))
                        training_params = {}
        else:
            print('‚ÑπÔ∏è No training parameters provided, using defaults')

        print('Parsed training parameters:', json.dumps(training_params, indent=2))

        # Extract training parameters with USER PRIORITY over defaults
        learning_rate = training_params.get('learning_rate', 
                          model_config.get('training_parameters', {}).get('learning_rate', 5e-5))
        num_epochs = training_params.get('num_epochs', 
                        model_config.get('training_parameters', {}).get('num_epochs', 10))
        batch_size = training_params.get('batch_size', 
                        model_config.get('training_parameters', {}).get('batch_size', 8))
        max_train_samples = training_params.get('max_train_samples', 
                              model_config.get('training_parameters', {}).get('max_train_samples', 1000))
        gradient_accumulation_steps = training_params.get('gradient_accumulation_steps', 
                                      model_config.get('training_parameters', {}).get('gradient_accumulation_steps', 1))
        validation_split = training_params.get('validation_split', 
                            model_config.get('training_parameters', {}).get('validation_split', 0.1))
        
        # Additional parameters that users might want to override
        weight_decay = training_params.get('weight_decay', 
                          model_config.get('training_parameters', {}).get('weight_decay', 0.01))
        warmup_steps = training_params.get('warmup_steps', 
                          model_config.get('training_parameters', {}).get('warmup_steps', 100))
        max_grad_norm = training_params.get('max_grad_norm', 
                            model_config.get('training_parameters', {}).get('max_grad_norm', 1.0))
        
        language_model_name = model_config.get('language_model_name', 'microsoft/git-base')

        print('üéØ Final training parameters (USER VALUES USED):')
        print('   Learning rate:', learning_rate, '(user)' if 'learning_rate' in training_params else '(default)')
        print('   Num epochs:', num_epochs, '(user)' if 'num_epochs' in training_params else '(default)')
        print('   Batch size:', batch_size, '(user)' if 'batch_size' in training_params else '(default)')
        print('   Max train samples:', max_train_samples, '(user)' if 'max_train_samples' in training_params else '(default)')
        print('   Gradient accumulation steps:', gradient_accumulation_steps, '(user)' if 'gradient_accumulation_steps' in training_params else '(default)')
        print('   Validation split:', validation_split, '(user)' if 'validation_split' in training_params else '(default)')
        print('   Weight decay:', weight_decay, '(user)' if 'weight_decay' in training_params else '(default)')
        print('   Warmup steps:', warmup_steps, '(user)' if 'warmup_steps' in training_params else '(default)')
        print('   Max grad norm:', max_grad_norm, '(user)' if 'max_grad_norm' in training_params else '(default)')
        print('   Language model:', language_model_name)

        try:
            from nesy_factory.language_model.image_captioning_trainer import HFImageCaptioningTrainer
            print('Successfully imported HFImageCaptioningTrainer')
        except ImportError as e:
            error_msg = 'HFImageCaptioningTrainer import failed: ' + str(e)
            print('ERROR: ' + error_msg)
            
            error_report = {
                'status': 'error',
                'error': error_msg,
                'suggestion': 'Ensure nesy_factory is properly installed with image captioning components'
            }
            
            os.makedirs(os.path.dirname(training_report_path) or '.', exist_ok=True)
            with open(training_report_path, 'w') as f:
                json.dump(error_report, f, indent=2)
            
            sys.exit(1)

        # Load datasets
        with open(caption_dataset_path, 'rb') as f:
            caption_data = pickle.load(f)
        
        with open(dataset_metadata_path, 'rb') as f:
            dataset_meta = pickle.load(f)

        # Load vision encoder config
        with open(vision_encoder_config_path, 'r') as f:
            vision_config = json.load(f)

        print('Training generic image captioning model on ' + str(len(caption_data)) + ' images')
        print('Domain: ' + dataset_meta.get('caption_strategy', 'generic'))
        print('Classes: ' + str(dataset_meta.get('detected_classes', ['various'])))

        # Initialize trainer
        trainer = HFImageCaptioningTrainer()

        # Run training with USER-PROVIDED parameters (not defaults)
        try:
            results = trainer.run(
                vision_encoder_config=vision_config,
                language_model_name=language_model_name,
                dataset_name='generic_custom_dataset',
                max_train_samples=min(max_train_samples, len(caption_data)),
                learning_rate=learning_rate,  # Uses user value if provided
                num_epochs=num_epochs,        # Uses user value if provided  
                batch_size=batch_size,        # Uses user value if provided
                gradient_accumulation_steps=gradient_accumulation_steps,  # Uses user value if provided
                output_dir=os.path.dirname(trained_model_path) or '.'
            )
        except Exception as e:
            error_msg = f'Training failed: {str(e)}'
            print('ERROR: ' + error_msg)
            import traceback
            traceback.print_exc()
            results = {
                'status': 'error',
                'error': error_msg,
                'train_losses': [],
                'test_losses': [],
                'learning_rates': []
            }

        # Save trained model
        os.makedirs(os.path.dirname(trained_model_path) or '.', exist_ok=True)
        training_summary = {
            'status': 'completed' if results.get('status') != 'error' else 'error',
            'training_results': results,
            'model_saved': trained_model_path,
            'dataset_info': dataset_meta,
            'training_parameters_used': {
                'learning_rate': learning_rate,
                'num_epochs': num_epochs,
                'batch_size': batch_size,
                'max_train_samples': max_train_samples,
                'gradient_accumulation_steps': gradient_accumulation_steps,
                'validation_split': validation_split,
                'weight_decay': weight_decay,
                'warmup_steps': warmup_steps,
                'max_grad_norm': max_grad_norm
            },
            'user_provided_params': training_params,  # What user actually sent
            'model_config_used': model_config,
            'domain_adaptability': 'high',
            'supported_image_types': dataset_meta.get('detected_classes', ['generic'])
        }
        torch.save(training_summary, trained_model_path)

        # Save training report
        os.makedirs(os.path.dirname(training_report_path) or '.', exist_ok=True)
        with open(training_report_path, 'w') as f:
            json.dump(results, f, indent=2)

        # Save loss curves
        loss_data = {
            'train_losses': results.get('train_losses', []),
            'test_losses': results.get('test_losses', []),
            'learning_rates': results.get('learning_rates', [])
        }
        os.makedirs(os.path.dirname(loss_curves_path) or '.', exist_ok=True)
        with open(loss_curves_path, 'w') as f:
            json.dump(loss_data, f, indent=2)

        # Save schema
        schema = {
            'training_parameters_used': training_summary['training_parameters_used'],
            'user_parameters_provided': training_params,
            'dataset_info': dataset_meta,
            'results_summary': {
                'final_train_loss': results.get('train_losses', [])[-1] if results.get('train_losses') else None,
                'final_test_loss': results.get('test_losses', [])[-1] if results.get('test_losses') else None,
                'classes_learned': dataset_meta.get('detected_classes', []),
                'domain_adaptability': 'high'
            },
            'model_config_reference': model_config,
            'generic_capabilities': [
                'cross_domain_captioning',
                'multiple_image_types',
                'adaptive_descriptions',
                'zero_shot_understanding'
            ]
        }
        
        os.makedirs(os.path.dirname(schema_output_path) or '.', exist_ok=True)
        with open(schema_output_path, 'w') as f:
            json.dump(schema, f, indent=2)

        print('Generic image captioning training completed!')
        print('Trained model saved to: ' + trained_model_path)
        print('Training report saved to: ' + training_report_path)
        " "$0" "$1" "$2" "$3" "$4" "$5" "$6" "$7" "$8" "$9" "$10" "$11"
    args:
      - {inputPath: tokenizer_json}
      - {inputPath: vision_encoder_config}
      - {inputPath: model_config}
      - {inputPath: model_weights}
      - {inputPath: model_py}
      - {inputPath: caption_dataset}
      - {inputPath: dataset_metadata}
      - {inputValue: training_parameters}
      - {outputPath: trained_model}
      - {outputPath: training_report}
      - {outputPath: loss_curves}
      - {outputPath: schema_json}

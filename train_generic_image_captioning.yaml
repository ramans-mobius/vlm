name: Train Generic Image Captioning - DEBUG VERSION
description: Debug version that prints library versions and identifies compatibility issues
inputs:
  - name: tokenizer_json
    type: Model
  - name: vision_encoder_config
    type: Data
  - name: model_config
    type: Data
  - name: model_weights
    type: Model
  - name: model_py
    type: Data
  - name: caption_dataset
    type: Dataset
  - name: dataset_metadata
    type: DatasetInfo
  - name: training_parameters
    type: String
    default: "{}"
outputs:
  - name: trained_model
    type: Model
  - name: training_report
    type: Data
  - name: loss_curves
    type: Data
  - name: schema_json
    type: Data
implementation:
  container:
    image: gurpreetgandhi/nesy-factory:v29
    command:
      - sh
      - -c
      - |
        python3 -c "
        import sys, os, json, pickle, base64, io
        from PIL import Image
        
        print('=== DEBUG: LIBRARY VERSIONS ===')
        
        # Print Python version
        print('Python version: ' + str(sys.version))
        
        # Try to import and print versions of key libraries
        libraries = [
            'torch', 'transformers', 'tokenizers', 'datasets', 
            'torchvision', 'PIL', 'numpy', 'tqdm'
        ]
        
        for lib in libraries:
            try:
                if lib == 'PIL':
                    import PIL
                    print(lib + ': ' + str(PIL.__version__))
                elif lib == 'torch':
                    import torch
                    print(lib + ': ' + str(torch.__version__))
                    print('CUDA available: ' + str(torch.cuda.is_available()))
                    if torch.cuda.is_available():
                        print('CUDA version: ' + str(torch.version.cuda))
                else:
                    module = __import__(lib)
                    version = getattr(module, '__version__', 'version not found')
                    print(lib + ': ' + str(version))
            except ImportError as e:
                print(lib + ': NOT INSTALLED - ' + str(e))
            except Exception as e:
                print(lib + ': Error getting version - ' + str(e))
        
        print('=== DEBUG: CHECKING TRANSFORMERS COMPATIBILITY ===')
        try:
            from transformers import AutoProcessor, AutoModelForCausalLM
            print('✓ AutoProcessor and AutoModelForCausalLM imported successfully')
            
            # Check if we can instantiate a processor
            try:
                processor = AutoProcessor.from_pretrained('microsoft/git-base')
                print('✓ AutoProcessor.from_pretrained works')
            except Exception as e:
                print('✗ AutoProcessor.from_pretrained failed: ' + str(e))
                
        except Exception as e:
            print('✗ Transformers import failed: ' + str(e))
            import traceback
            traceback.print_exc()
        
        print('=== DEBUG: CHECKING NESY-FACTORY COMPONENTS ===')
        try:
            from nesy_factory.language_model.vision_encoders import CLIPVisionEncoder
            print('✓ CLIPVisionEncoder imported successfully')
        except Exception as e:
            print('✗ CLIPVisionEncoder import failed: ' + str(e))
            import traceback
            traceback.print_exc()
        
        print('=== DEBUG: SYSTEM INFORMATION ===')
        print('Current working directory: ' + str(os.getcwd()))
        print('Python executable: ' + str(sys.executable))
        print('System path: ' + str(sys.path))
        
        # Now continue with the actual training logic...
        print('=== STARTING ACTUAL TRAINING LOGIC ===')
        
        # Get arguments from command line
        tokenizer_json_path = sys.argv[1]
        vision_encoder_config_path = sys.argv[2]
        model_config_path = sys.argv[3]
        model_weights_path = sys.argv[4]
        model_py_path = sys.argv[5]
        caption_dataset_path = sys.argv[6]
        dataset_metadata_path = sys.argv[7]
        training_params_str = sys.argv[8]
        trained_model_path = sys.argv[9]
        training_report_path = sys.argv[10]
        loss_curves_path = sys.argv[11]
        schema_output_path = sys.argv[12]

        print('Starting generic image captioning training...')
        
        # Parse training parameters
        try:
            training_params = json.loads(training_params_str) if training_params_str.strip() not in ['{}', ''] else {}
        except json.JSONDecodeError as e:
            print('WARN: Invalid training_params JSON: ' + str(e) + ', using empty config')
            training_params = {}

        # Load configurations
        with open(vision_encoder_config_path, 'r') as f:
            vision_config = json.load(f)
        
        with open(model_config_path, 'r') as f:
            model_cfg = json.load(f)

        # Load dataset
        try:
            with open(caption_dataset_path, 'rb') as f:
                caption_data = pickle.load(f)
            print('Loaded caption dataset with ' + str(len(caption_data)) + ' samples')
        except Exception as e:
            print('Failed to load caption dataset: ' + str(e))
            caption_data = []

        # Simplified training simulation
        print('Simulating training process...')
        
        # Create dummy training report
        report = {
            'status': 'debug_completed',
            'epochs_completed': 0,
            'final_loss': 0.0,
            'training_samples': len(caption_data),
            'library_versions_checked': True,
            'compatibility_issues_found': 'see_debug_output'
        }

        # Create dummy loss curves
        loss_data = {
            'epochs': [1, 2, 3],
            'train_loss': [2.5, 1.8, 1.2],
            'val_loss': [2.7, 2.0, 1.5]
        }

        # Save outputs
        os.makedirs(os.path.dirname(trained_model_path) or '.', exist_ok=True)
        with open(trained_model_path, 'w') as f:
            json.dump({'status': 'debug_model', 'message': 'Training completed in debug mode'}, f)

        os.makedirs(os.path.dirname(training_report_path) or '.', exist_ok=True)
        with open(training_report_path, 'w') as f:
            json.dump(report, f, indent=2)

        os.makedirs(os.path.dirname(loss_curves_path) or '.', exist_ok=True)
        with open(loss_curves_path, 'w') as f:
            json.dump(loss_data, f, indent=2)

        schema = {
            'training_status': 'debug_completed',
            'compatibility_check': 'performed',
            'next_steps': 'check_debug_output_for_issues'
        }
        
        os.makedirs(os.path.dirname(schema_output_path) or '.', exist_ok=True)
        with open(schema_output_path, 'w') as f:
            json.dump(schema, f, indent=2)

        print('Debug training completed successfully!')
        print('Check the debug output above for library compatibility issues.')
        " "$0" "$1" "$2" "$3" "$4" "$5" "$6" "$7" "$8" "$9" "$10" "$11" "$12"
    args:
      - {inputPath: tokenizer_json}
      - {inputPath: vision_encoder_config}
      - {inputPath: model_config}
      - {inputPath: model_weights}
      - {inputPath: model_py}
      - {inputPath: caption_dataset}
      - {inputPath: dataset_metadata}
      - {inputValue: training_parameters}
      - {outputPath: trained_model}
      - {outputPath: training_report}
      - {outputPath: loss_curves}
      - {outputPath: schema_json}
